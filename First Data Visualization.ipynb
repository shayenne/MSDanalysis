{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### \n",
    "#    Data Science Project - 2017\n",
    "#    \n",
    "#    Million Song Dataset: Analysis and Correlations\n",
    "#\n",
    "#    Authors: Shayenne Moura, Thais Neubauer and Marcos Leal\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Data Visualization\n",
    "\n",
    "We need to make a detailed description of each data used on this visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrape categories shows data content and metadata\n",
    "import scrape_categories as sc\n",
    "from model import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " 'bs',\n",
       " 'get_possible_categories',\n",
       " 'urlopen']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - artist_mbid: db92a151-1ac2-438b-bc43-b82e149ddd50 \n",
      "the musicbrainz.org ID for this artists is db9... \n",
      "\n",
      "1 - artist_mbtags: shape = (4,) \n",
      "this artist received 4 tags on musicbrainz.org \n",
      "\n",
      "2 - artist_mbtags_count: shape = (4,) \n",
      "raw tag count of the 4 tags this artist received on musicbrainz.org \n",
      "\n",
      "3 - artist_name: Rick Astley \n",
      "artist name \n",
      "\n",
      "4 - artist_playmeid: 1338 \n",
      "the ID of that artist on the service playme.com \n",
      "\n",
      "5 - artist_terms: shape = (12,) \n",
      "this artist has 12 terms (tags) from The Echo Nest \n",
      "\n",
      "6 - artist_terms_freq: shape = (12,) \n",
      "frequency of the 12 terms from The Echo Nest (number between 0 and 1) \n",
      "\n",
      "7 - artist_terms_weight: shape = (12,) \n",
      "weight of the 12 terms from The Echo Nest (number between 0 and 1) \n",
      "\n",
      "8 - audio_md5: bf53f8113508a466cd2d3fda18b06368 \n",
      "hash code of the audio used for the analysis by The Echo Nest \n",
      "\n",
      "9 - bars_confidence: shape = (99,) \n",
      "confidence value (between 0 and 1) associated with each bar by The Echo Nest \n",
      "\n",
      "10 - bars_start: shape = (99,) \n",
      "start time of each bar according to The Echo Nest, this song has 99 bars \n",
      "\n",
      "11 - beats_confidence: shape = (397,) \n",
      "confidence value (between 0 and 1) associated with each beat by The Echo Nest \n",
      "\n",
      "12 - beats_start: shape = (397,) \n",
      "start time of each beat according to The Echo Nest, this song has 397 beats \n",
      "\n",
      "13 - danceability: 0.0 \n",
      "danceability measure of this song according to The Echo Nest (between 0 and 1, 0 => not analyzed) \n",
      "\n",
      "14 - duration: 211.69587 \n",
      "duration of the track in seconds \n",
      "\n",
      "15 - end_of_fade_in: 0.139 \n",
      "time of the end of the fade in, at the beginning of the song, according to The Echo Nest \n",
      "\n",
      "16 - energy: 0.0 \n",
      "energy measure (not in the signal processing sense) according to The Echo Nest (between 0 and 1, 0 => not analyzed) \n",
      "\n",
      "17 - key: 1 \n",
      "estimation of the key the song is in by The Echo Nest \n",
      "\n",
      "18 - key_confidence: 0.324 \n",
      "confidence of the key estimation \n",
      "\n",
      "19 - loudness: -7.75 \n",
      "general loudness of the track \n",
      "\n",
      "20 - mode: 1 \n",
      "estimation of the mode the song is in by The Echo Nest \n",
      "\n",
      "21 - mode_confidence: 0.434 \n",
      "confidence of the mode estimation \n",
      "\n",
      "22 - release: Big Tunes - Back 2 The 80s \n",
      "album name from which the track was taken, some songs / tracks can come from many albums, we give only one \n",
      "\n",
      "23 - release_7digitalid: 786795 \n",
      "the ID of the release (album) on the service 7digital.com \n",
      "\n",
      "24 - sections_confidence: shape = (10,) \n",
      "confidence value (between 0 and 1) associated with each section by The Echo Nest \n",
      "\n",
      "25 - sections_start: shape = (10,) \n",
      "start time of each section according to The Echo Nest, this song has 10 sections \n",
      "\n",
      "26 - segments_confidence: shape = (935,) \n",
      "confidence value (between 0 and 1) associated with each segment by The Echo Nest \n",
      "\n",
      "27 - segments_loudness_max: shape = (935,) \n",
      "max loudness during each segment \n",
      "\n",
      "28 - segments_loudness_max_time: shape = (935,) \n",
      "time of the max loudness during each segment \n",
      "\n",
      "29 - segments_loudness_start: shape = (935,) \n",
      "loudness at the beginning of each segment \n",
      "\n",
      "30 - segments_pitches: shape = (935, 12) \n",
      "chroma features for each segment (normalized so max is 1.) \n",
      "\n",
      "31 - segments_start: shape = (935,) \n",
      "start time of each segment (~ musical event, or onset) according to The Echo Nest, this song has 935 segments \n",
      "\n",
      "32 - segments_timbre: shape = (935, 12) \n",
      "MFCC-like features for each segment \n",
      "\n",
      "33 - similar_artists: shape = (100,) \n",
      "a list of 100 artists (their Echo Nest ID) similar to Rick Astley according to The Echo Nest \n",
      "\n",
      "34 - song_hotttnesss: 0.864248830588 \n",
      "according to The Echo Nest, when downloaded (in December 2010), this song had a 'hotttnesss' of 0.8 (on a scale of 0 and 1) \n",
      "\n",
      "35 - song_id: SOCWJDB12A58A776AF \n",
      "The Echo Nest song ID, note that a song can be associated with many tracks (with very slight audio differences) \n",
      "\n",
      "36 - start_of_fade_out: 198.536 \n",
      "start time of the fade out, in seconds, at the end of the song, according to The Echo Nest \n",
      "\n",
      "37 - tatums_confidence: shape = (794,) \n",
      "confidence value (between 0 and 1) associated with each tatum by The Echo Nest \n",
      "\n",
      "38 - tatums_start: shape = (794,) \n",
      "start time of each tatum according to The Echo Nest, this song has 794 tatums \n",
      "\n",
      "39 - tempo: 113.359 \n",
      "tempo in BPM according to The Echo Nest \n",
      "\n",
      "40 - time_signature: 4 \n",
      "time signature of the song according to The Echo Nest, i.e. usual number of beats per bar \n",
      "\n",
      "41 - time_signature_confidence: 0.634 \n",
      "confidence of the time signature estimation \n",
      "\n",
      "42 - title: Never Gonna Give You Up \n",
      "song title \n",
      "\n",
      "43 - track_7digitalid: 8707738 \n",
      "the ID of this song on the service 7digital.com \n",
      "\n",
      "44 - track_id: TRAXLZU12903D05F94 \n",
      "The Echo Nest ID of this particular track on which the analysis was done \n",
      "\n",
      "45 - year: 1987 \n",
      "year when this song was released, according to musicbrainz.org \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.get_possible_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to ./temp/song_data1.csv99% ] ==== \n",
      "duration           3.379673\n",
      "key               -0.008369\n",
      "song_hotttnesss   -0.029363\n",
      "tempo              0.411232\n",
      "time_signature    -0.590469\n",
      "dtype: float64\n",
      "                 duration       key  song_hotttnesss     tempo  time_signature\n",
      "duration         1.000000  0.015262         0.007042 -0.009968        0.111448\n",
      "key              0.015262  1.000000         0.025952  0.009821        0.003124\n",
      "song_hotttnesss  0.007042  0.025952         1.000000  0.079031        0.041059\n",
      "tempo           -0.009968  0.009821         0.079031  1.000000        0.055251\n",
      "time_signature   0.111448  0.003124         0.041059  0.055251        1.000000\n",
      "Done. Time elapsed: 0.0998840332031\n"
     ]
    }
   ],
   "source": [
    "# If you run for again, use the file created \n",
    "basic_info(categories=[\"tempo\",\"duration\",\"key\",\"time_signature\",\"song_hotttnesss\"], saved_csv=None)#\"./temp/song_data1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to ./temp/song_data.csv.99% ] ==== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/compmus/.local/lib/python2.7/site-packages/mpl_toolkits/basemap/__init__.py:3260: MatplotlibDeprecationWarning: The ishold function was deprecated in version 2.0.\n",
      "  b = ax.ishold()\n",
      "/home/compmus/.local/lib/python2.7/site-packages/mpl_toolkits/basemap/__init__.py:3269: MatplotlibDeprecationWarning: axes.hold is deprecated.\n",
      "    See the API Changes document (http://matplotlib.org/api/api_changes.html)\n",
      "    for more details.\n",
      "  ax.hold(b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Time elapsed: 22.1568899155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad924e8dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Artist Locations from latitude/longitude\n",
    "\n",
    "# If you run for again, use the file created \n",
    "world_plot(lat=\"artist_latitude\",lon=\"artist_longitude\", saved_csv=None)#\"./temp/song_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to ./temp/song_data.csv.99% ] ==== \n",
      "Done. Time elapsed: 2.46926689148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad92843910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalized % Frequency for each year\n",
    "\n",
    "# If you run for again, use the file created \n",
    "freq_plot(category=\"year\", saved_csv=None)#\"./temp/song_data3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to ./temp/song_data.csv.99% ] ==== \n",
      "Done. Time elapsed: 1.49211978912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad928ca790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Duration of Songs\n",
    "\n",
    "# If you run for again, use the file created \n",
    "stacked_barplot(full=\"duration\",head_end=\"end_of_fade_in\",tail_start=\"start_of_fade_out\", saved_csv=None)#\"./temp/song_data4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to ./temp/song_data.csv.99% ] ==== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.py:188: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_x = df_clean[df[categories[0]] == x_i] # df containing all entries with x in categories[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Time elapsed: 2.76592206955\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYfAlqQmDL0lNGHxJauJ/Acz2XLpusNoKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff413cc6c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Average 'artist_hotttnesss' Over Time\n",
    "\n",
    "# If you run for again, use the file created \n",
    "compare_to_average(x_cat=\"year\",y_cat=\"artist_hotttnesss\", saved_csv=None)#\"./temp/song_data5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Time elapsed: 0.3295309543610.00% ] ==== \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b7b0b61d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Segment Max Loudness\n",
    "\n",
    "# If you run for again, use the file created \n",
    "error_bar(categories=[\"segments_loudness_max\",\"segments_confidence\"],data_i=[0,1],sec_i=[0,100], saved_csv=None)#\"./temp/song_data6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6280c48310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "# If you run for again, use the file created \n",
    "dr(x_categories=[\"key\",\"loudness\",\"mode\",\"tempo\",\"year\"],y_category=[\"artist_mbtags\",\"artist_mbtags_count\"],saved_csv=None)#\"./temp/song_data7.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to evaluate the Dataset (We need to decide to apply only at the sample or all dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. For each artist, what is the most commonly tagged genre?\n",
    "\n",
    "Q2. What is the average tempo across all the songs in the dataset?\n",
    "\n",
    "Q3. What is the median danceability score across all the songs in the dataset?\n",
    "\n",
    "Q4. Who are the top ten artists for fast songs (based on their tempo)?\n",
    "\n",
    "Q5. What  are top  ten  songs  based  on  their  hotness  in  each  genre? Please also \n",
    "provide the artist name and title for these songs.\n",
    "\n",
    "Q6. On a per-year basis, what is the mean variance of loudness across the songs within the dataset?\n",
    "\n",
    "Q7. How many songs does each artist have in this dataset?    \n",
    "\n",
    "Q8. What are the top ten most popular terms (genres) that songs in the dataset have been tagged with?\n",
    "\n",
    "Q9. Come up with an innovative analysis program for this dataset. For this component, think of yourself as the lead data scientist at a start-up firm. What would do with this dataset that is cool?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and Paul Lamere. The Million Song Dataset. In Proceedings of the 12th International Society for Music Information Retrieval Conference (ISMIR 2011), 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "CODE REFERENCE: https://github.com/eltonlaw/msdvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
